{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "513bb501-1f6a-472c-8fb4-48a17ffeb9eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extracting meaningful lines from 'Alchemy of Souls' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92308e6-8467-42d9-91af-3e49399b081f",
   "metadata": {},
   "source": [
    "Loading the libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d344caa2-db12-47ca-890a-68c471a32d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df_ep19 = pd.read_csv('https://raw.githubusercontent.com/dduyg/alchemy-of-souls/main/data/raw-data/alchemyofsouls_S01E19.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0494e397-2f38-4c0f-9165-414ac8692036",
   "metadata": {},
   "source": [
    "Preprocessing the text data by removing any unwanted characters, punctuation, and stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf785572-81cd-434f-8e72-84fbbec61157",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() # convert to lowercase\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # remove punctuation\n",
    "    tokens = word_tokenize(text) # tokenize the text\n",
    "    tokens = [word for word in tokens if not word in stop_words] # remove stop words\n",
    "    clean_text = ' '.join(tokens)\n",
    "    return clean_text\n",
    "\n",
    "df_ep19['clean_text'] = df_ep19['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a967ff8-e7b5-4d33-ab4a-eb3ac0dd1050",
   "metadata": {},
   "source": [
    "Using a topic modeling technique like Latent Dirichlet Allocation (LDA) to extract themes and messages from the preprocessed text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37ee41bd-1b7f-453b-863d-2fdf3998709a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.9/site-packages (4.3.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.9/site-packages (from gensim) (1.22.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.9/site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.9/site-packages (from gensim) (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# create a dictionary\n",
    "dictionary = corpora.Dictionary(df_ep19['clean_text'].apply(lambda x: x.split()))\n",
    "\n",
    "# create a corpus\n",
    "corpus = [dictionary.doc2bow(text.split()) for text in df_ep19['clean_text']]\n",
    "\n",
    "# train the LDA model\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7fa58d-eb7c-4a4c-aaa9-1894ddb7ce37",
   "metadata": {},
   "source": [
    "The top 5 topics and the top words in each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f1a88f2-d9b9-42c5-abb5-d455c2992eed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.031*\"ice\" + 0.029*\"stone\" + 0.012*\"jinyowon\" + 0.012*\"body\" + 0.012*\"like\" + 0.011*\"jang\" + 0.010*\"mage\" + 0.010*\"know\" + 0.009*\"would\" + 0.009*\"soul\"\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.021*\"jang\" + 0.018*\"power\" + 0.015*\"father\" + 0.013*\"master\" + 0.013*\"gang\" + 0.011*\"energy\" + 0.010*\"use\" + 0.009*\"must\" + 0.009*\"put\" + 0.009*\"us\"\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.020*\"master\" + 0.018*\"mudeok\" + 0.013*\"die\" + 0.010*\"like\" + 0.010*\"sorcery\" + 0.010*\"everyone\" + 0.009*\"power\" + 0.009*\"also\" + 0.009*\"get\" + 0.008*\"soul\"\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.024*\"stone\" + 0.021*\"ice\" + 0.010*\"jin\" + 0.008*\"need\" + 0.008*\"going\" + 0.007*\"told\" + 0.007*\"soul\" + 0.007*\"take\" + 0.007*\"found\" + 0.007*\"become\"\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.017*\"star\" + 0.016*\"kings\" + 0.013*\"us\" + 0.013*\"right\" + 0.012*\"let\" + 0.011*\"body\" + 0.010*\"get\" + 0.009*\"uk\" + 0.009*\"souls\" + 0.009*\"person\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the topics and the top words in each topic\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(f\"Topic: {idx} \\nWords: {topic}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca0701b-0b0d-49cc-90a8-88403d0a7802",
   "metadata": {},
   "source": [
    "Using the LDA model to assign topics to each line in the dataframe and then filter the lines that belong to the relevant topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c4f80ed-d0fa-4692-8d5c-8d5f356c03b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_topic(text):\n",
    "    bow = dictionary.doc2bow(text.split())\n",
    "    topic = max(lda_model[bow], key=lambda x: x[1])[0]\n",
    "    return topic\n",
    "\n",
    "df_ep19['topic'] = df_ep19['clean_text'].apply(get_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3121f4-14e7-4222-8dbf-aa71c0c405a1",
   "metadata": {},
   "source": [
    "The meaningful, iconic lines that contain valuable messages/lessons from the relevant topics identified by the LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edc3a27b-3b0c-4d5f-aaf7-956e432b7a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5                                  Yes, it has to be it.\n",
      "9              through the great power of the ice stone.\n",
      "11     It explains why he performed sorcery\\nto save ...\n",
      "14     a good-for-nothing man like me\\nwas able to marry\n",
      "16                      So I guess I should be grateful.\n",
      "                             ...                        \n",
      "929                           despite how lacking I was.\n",
      "930                                          I know that\n",
      "931      you gave up your chance\\nto regain your energy.\n",
      "936                             I, Mu-deok, your master,\n",
      "939                                   Marry me, Mu-deok.\n",
      "Name: text, Length: 427, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# find the meaningful, iconic lines that belong to the relevant topics\n",
    "relevant_topics = [0, 2] # replace with the relevant topics identified from the LDA model\n",
    "iconic_lines = df_ep19[df_ep19['topic'].isin(relevant_topics)]['text']\n",
    "print(iconic_lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
